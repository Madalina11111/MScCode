# -*- coding: utf-8 -*-
"""Calculate average cosine distance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10m_nNmgZMW6KaF7FtFhCI5fqt6PjLMJm
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt

from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img
import cv2

from keras.applications import inception_v3
from keras.applications.inception_v3 import InceptionV3

from keras.layers import Dense, GlobalAveragePooling2D
from keras.models import Model

from numpy import load

from sklearn.metrics.pairwise import cosine_similarity

from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.inception_v3 import preprocess_input

import os

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

#load images from npz
def load_real_samples(filename):
  data = load(filename)
  X = data['arr_0']
  print(X.shape)
  X = X.astype('float32')
  return X

#one way of extracting features
#base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")

#predictions_all_images = []
#all_x = []
#proli_dir = "/content/gdrive/My Drive/Kaggle/proli"
#for new_img in os.listdir(proli_dir):

#  img_path = proli_dir + "/" + new_img
#  img = image.load_img(img_path) #, target_size=(128, 128))
#  x = image.img_to_array(img)
#  #x = np.expand_dims(x, axis=0)
#  all_x.append(x)
#all_x = np.asarray(all_x)

#predictions = base_model.predict(all_x)



#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class4 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/Kaggle_training_images_in_order_preprocessed_class4_normalized3.npz")
predictions_class4 = base_model.predict(class4)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class4.shape[0]):
  for j in range(predictions_class4.shape[0]):
    if(i != j):
      cosine_distance_sum += distance.cosine(predictions_class4[i], predictions_class4[j])
print(cosine_distance_sum/(predictions_class4.shape[0] * predictions_class4.shape[0] - predictions_class4.shape[0]))



#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_0_2nd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_1_2nd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_2_2nd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_3_2nd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_4_2nd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_0_3nd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_1_3rd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_2_3rd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_3_3rd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_4_3rd_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))



#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_0_4th_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_1_4th_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_2_4th_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_3_4th_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed 2/random_selected_preprocessed_real_class_4_4th_time.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))









#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
class0 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/training_preprocessed_fake_class_4.npz")
predictions_class0 = base_model.predict(class0)

class1 = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/randomly selected Kaggle preprocessed/training_preprocessed_real_randomly_selected_class_0.npz")
predictions_class1 = base_model.predict(class1)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions_class0.shape[0]):
  for j in range(predictions_class1.shape[0]):
    cosine_distance_sum += distance.cosine(predictions_class0[i], predictions_class1[j])
print(cosine_distance_sum/(predictions_class0.shape[0] * predictions_class1.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_9.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_19.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_29.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_39.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_49.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_59.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_69.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_79.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_89.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_99.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_109.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_119.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_129.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_139.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_149.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_159.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_169.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_179.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_189.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_199.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_209.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_219.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_229.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_239.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_249.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_259.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_269.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_279.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_289.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_299.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_309.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_319.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_329.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_339.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_349.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_359.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_369.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_379.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_389.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_399.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_409.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_419.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_429.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_439.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_449.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_459.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_469.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_479.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_489.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))

#another way of extracting features. This is better
base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(128, 128, 3) , pooling="avg", classifier_activation="softmax")
trainX = load_real_samples("/content/gdrive/My Drive/MSc. project/npz files conference/real + fake IDRiD/real+fake_IDRID_epoch_499.npz")
predictions = base_model.predict(trainX)

from scipy.spatial import distance
cosine_distance_sum = 0
for i in range (predictions.shape[0]):
  for j in range(predictions.shape[0]):
    cosine_distance_sum += distance.cosine(predictions[i], predictions[j])
print(cosine_distance_sum/(predictions.shape[0] * predictions.shape[0]))